{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E32UBMT7VKMm"
      },
      "source": [
        "## Prepare python environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The specified version of pomegranate is necessary, so please do not modify it. It may take more than 5-10 mins to install these packages, so please be patient."
      ],
      "metadata": {
        "id": "nOYbgt4_qQGw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1AE75bhOCao"
      },
      "source": [
        "# Installs required packages\n",
        "!apt install libgraphviz-dev\n",
        "!pip install pomegranate==0.15.0\n",
        "!pip install matplotlib pygraphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_lm7Q-9VKMn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryOZJYQa3PG0"
      },
      "source": [
        "random_state=5 # use this to control randomness across runs e.g., dataset partitioning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BASGXrOy4wat"
      },
      "source": [
        "## Preparing the Statslog (Heart) Dataset (2 points)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We will use heart dataset from UCI machine learning repository. Details of this data can be found [here](https://archive.ics.uci.edu/ml/datasets/statlog+(heart)).\n",
        "The dataset contains the following features with their corresponding feature types:\n",
        "1. age in years (real)\n",
        "2. sex (binary; 1=male/0=female)\n",
        "3. cp: chest pain type (categorical)\n",
        "4. trestbps: resting blood pressure (in mm Hg on admission to the hospital) (real)\n",
        "5. chol: serum cholestorol in mg/dl (real)\n",
        "6. fbs: (fasting blood sugar > 120 mg/dl) (binary; 1=true/0=false)\n",
        "7. restecg: resting electrocardiographic results (categorical)\n",
        "8. thalach: maximum heart rate achieved (real)\n",
        "9. exang: exercise induced angina (1 = yes; 0 = no) (binary)\n",
        "10. oldpeak: ST depression induced by exercise relative to rest (real)\n",
        "11. slope: the slope of the peak exercise ST segment (ordinal)\n",
        "12. ca: number of major vessels colored by flourosopy (real)\n",
        "13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect. (categorical)\n",
        "\n",
        "The objective is to determine whether a person has heart disease or not based on these features.\n",
        "\n",
        "Note: We will use a subset of the above features because the [scikit-learn implementation of Decision Trees does not support categorical variables](https://scikit-learn.org/stable/modules/tree.html#tree)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URgO9HCN6RCl"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### There are a total of 303 entries in this dataset. First 13 columns are features and the last column indicates whether the person has heart disease or not."
      ],
      "metadata": {
        "id": "28d5x_HWlafo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load the dataset\n",
        "import os\n",
        "if not os.path.exists('heart.csv'):\n",
        "    !wget https://raw.githubusercontent.com/JHA-Lab/ece364_2022/master/dataset/heart.csv\n",
        "df = pd.read_csv('heart.csv')\n",
        "\n",
        "\n",
        "# keep real valued features and the target feature\n",
        "ind_non_categorical_features=np.array([0,3,4,7,9,11,-1])\n",
        "non_categorical_features=df.columns[ind_non_categorical_features]\n",
        "\n",
        "df=df[non_categorical_features]\n",
        "\n",
        "FEATURE_NAMES=df.drop('target',axis=1).columns\n",
        "\n",
        "# Display the first five instances in the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jOxH0lu4lSBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the datatype of each column\n",
        "df.info()"
      ],
      "metadata": {
        "id": "9ji4XY3ilWvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqAbo9DP2dOO"
      },
      "source": [
        "#### Look at some statistics of the data using the `describe` function in pandas. See [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) details about this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWOGkp8P2abU"
      },
      "source": [
        "# Display some statistics of the data\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Count tells us the number of Non-empty rows in a feature.\n",
        "\n",
        "2. Mean tells us the mean value of that feature.\n",
        "\n",
        "3. Std tells us the Standard Deviation Value of that feature.\n",
        "\n",
        "4. Min tells us the minimum value of that feature.\n",
        "\n",
        "5. 25%, 50%, and 75% are the percentile/quartile of each feature.\n",
        "\n",
        "6. Max tells us the maximum value of that feature."
      ],
      "metadata": {
        "id": "FrdPlwcolq0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Look at the distributions of some features across the population. See [here](https://seaborn.pydata.org/generated/seaborn.distplot.html) for details. These have been done for you."
      ],
      "metadata": {
        "id": "x0nxPN1Rlu6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['thalach'],bins=30,color='red',stat=\"density\",kde=True)"
      ],
      "metadata": {
        "id": "3Lzcll4Ylvli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['chol'],bins=30,color='green',stat='density',kde=True)"
      ],
      "metadata": {
        "id": "98kh3PKrlyTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['trestbps'],bins=30,color='blue',stat='density',kde=True)"
      ],
      "metadata": {
        "id": "NgaqsHMul2Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot histogram of heart disease with age. This has been done for you."
      ],
      "metadata": {
        "id": "FzfjIdHTl5x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.countplot(x='age',data = df, hue = 'target',palette='coolwarm_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PG2j3_FAl6jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRhEcln77rIK"
      },
      "source": [
        "### Extract target and descriptive features (1 point)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blhp_Upk8E-Y"
      },
      "source": [
        "#split dataset into features and target variable\n",
        "X = # insert your code here\n",
        "y = # insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5XDDMPY6t9U"
      },
      "source": [
        "# Convert data to numpy array\n",
        "X = # insert your code here\n",
        "y = # insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-JPYSnc8JQi"
      },
      "source": [
        "### Create training and validation datasets (1 point)\n",
        "\n",
        "Split the data into training and validation sets using `train_test_split`.  See [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for details. To get consistent result while splitting, set `random_state` to the value defined earlier. We use 80% of the data for training and 20% of the data for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzTzI3iT8R5x"
      },
      "source": [
        "X_train,X_val,y_train,y_val = # insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the dependency between features (2 points)"
      ],
      "metadata": {
        "id": "q1Mh__LfGITs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to check whether or not the two features, **thalach** and **chol**, are independent from each other. For simplicity, we probe P(140$\\leq$ **thalach** $\\leq$160), P(200$\\leq$ **chol** $\\leq$250), and P(140$\\leq$ **thalach** $\\leq$160, 200$\\leq$ **chol** $\\leq$250) to represent P(**thalach**), P(**chol**), and P(**thalach**,**chol**), respectively. Calculate them and comment on the dependency between **thalach** and **chol**."
      ],
      "metadata": {
        "id": "lJvUqGqkGMEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here"
      ],
      "metadata": {
        "id": "4-8enYxFGMu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANS:**"
      ],
      "metadata": {
        "id": "2bud8WPbGUCu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQTCntOk6t9W"
      },
      "source": [
        "## Training probability-based classifiers (16 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDcVqRS56t9X"
      },
      "source": [
        "### Exercise 1: Learning a Naive Bayes Model (7 points)\n",
        "\n",
        "#### We will use the `pomegranate` library to train a Naive Bayes Model. Review ch.6 and see [here](https://pomegranate.readthedocs.io/en/v0.8.1/NaiveBayes.html) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjrqGWte6t9X"
      },
      "source": [
        "from pomegranate.distributions import NormalDistribution, ExponentialDistribution, DiscreteDistribution\n",
        "from pomegranate.NaiveBayes import NaiveBayes\n",
        "from pomegranate.BayesClassifier import BayesClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "import math\n",
        "\n",
        "np.random.seed(random_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wkS5cL56t9Y"
      },
      "source": [
        "#### Exercise 1a: Fit naive bayes model using a single distribution type (1 point)\n",
        "\n",
        "#### Train one naive bayes model using a normal distribution per feature. Train another naive bayes model using an exponential distribution per feature. Hint: use NormalDistribution or ExponentialDistribution and NaiveBayes.from_samples() to fit the model to the data.\n",
        "\n",
        "#### Report the training and validation set accuracies for each model. Hint: use accuracy_score()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeAiEwIs6t9Y"
      },
      "source": [
        "# insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnm7xIL86t9Z"
      },
      "source": [
        "#### Exercise 1b: Fit a naive bayes model using different feature distributions (2 points)\n",
        "\n",
        "#### Visualize the feature distributions (done for you below) to determine which distribution (normal or exponential) better models a specific feature.\n",
        "\n",
        "#### Train a Naive Bayes classifier using this set of feature-specific distributions. Hint: use NormalDistribution or ExponentialDistribution and NaiveBayes.from_samples() to fit the model to the data.\n",
        "\n",
        "#### Report the training and validation set accuracies for the model. Hint: use accuracy_score()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mREYMrmg6t9Z"
      },
      "source": [
        "# visualization code\n",
        "\n",
        "num_cols=3\n",
        "num_rows=int(len(FEATURE_NAMES)/num_cols) if len(FEATURE_NAMES)%num_cols == 0 else int(math.ceil(len(FEATURE_NAMES)/num_cols))\n",
        "fig,ax=plt.subplots(num_rows,num_cols)\n",
        "\n",
        "for ft_index in np.arange(X_train.shape[1]):\n",
        "    ax[ft_index//num_cols,ft_index%num_cols].hist(X_train[:,ft_index], color='blue')\n",
        "    ax[ft_index//num_cols,ft_index%num_cols].hist(X_val[:,ft_index], color='red')\n",
        "    ax[ft_index//num_cols,ft_index%num_cols].set_title(FEATURE_NAMES[ft_index])\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lZTGhq16t9Z"
      },
      "source": [
        "# insert your code here: train a classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJqOu9je6t9a"
      },
      "source": [
        "#### Comment on any performance difference between this model and the models trained in Ex. 1a. (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsYqGS4k6t9a"
      },
      "source": [
        "**ANS:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVA5ZzhI6t9b"
      },
      "source": [
        "#### Exercise 1c: Fit a naive bayes model on categorical features (2 points)\n",
        "\n",
        "#### Besides fitting a naive bayes model on the continuous features, one can fit a naive bayes model on categorical features derived from binning the continuous features, and then compute a probability mass function for each categorical feature.\n",
        "\n",
        "#### Bin the features by varying the strategy among {equal-width binning, equal-frequency binning}. For each binning strategy, vary the number of bins among {3,10,50}. Hint: use [KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer.get_params) by modifying n_bins and strategy and setting encode=\"ordinal\" to map the labels to numerical categories.\n",
        "\n",
        "#### For each binning setting tried above, fit a naive bayes model on the binned version of the training set. Hint: use DiscreteDistribution to model the categorical features and NaiveBayes.from_samples() to fit the model to the data.\n",
        "\n",
        "#### Report the training and validation set accuracy for each model trained and evaluated on binned versions of the training and validation sets respectively.\n",
        "\n",
        "**Note:** You may see some \"UserWarning\"s when you run your code in this part. You can ignore them if you believe they won't affect your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "_oEKSVJ86t9b"
      },
      "source": [
        "# insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu_rVaWw6t9b"
      },
      "source": [
        "#### Briefly explain any performance difference between equal-width and equal-frequency binning. Also comment on the effect of increasing the number of bins (see ch.3). (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eP9xnHa6t9c"
      },
      "source": [
        "**ANS:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP6z3W4K6t9c"
      },
      "source": [
        "### Exercise 2: Learning a Bayes Net (9 points)\n",
        "\n",
        "#### We will use the `pomegranate` library to train a Bayes Net to assess whether relaxing the assumption in Naive bayes (i.e., all features are independent given the target feature) could improve the classification model. Review ch.6 and see [here](https://pomegranate.readthedocs.io/en/v0.8.1/BayesianNetwork.html) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6LhAf7J6t9c"
      },
      "source": [
        "#### Exercise 2a: Create a categorical version of the dataset (1 point)\n",
        "\n",
        "#### Create categorical versions of the training and validation sets by using equal-frequency binning with the number of bins set to 3 (as in Ex. 1c).\n",
        "\n",
        "#### Use these datasets for training and evaluating the bayes net models in the following exercises.\n",
        "\n",
        "**Note:** This is done because pomegranate currently only supports bayes net over categorical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwTP_x2I6t9c"
      },
      "source": [
        "# insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqPAKILl6t9c"
      },
      "source": [
        "#### Exercise 2b: Construct a Bayes net (3 points)\n",
        "\n",
        "#### Construct and train a Bayes net in which the **trestbps** (resting blood pressure) feature node is a parent of the **heart disease** feature node (only these 2 nodes should be in the net). Use construct_and_train_bayes_net (defined below) by passing in the binned training dataset and specifying the index of the parent feature node.\n",
        "\n",
        "#### Construct and train another Bayes net in which the **ca** (number of major vessels colored by flourosopy) feature node is a parent of the **heart disease** feature node (only these 2 nodes should be in the net). Use construct_and_train_bayes_net (defined below) by passing in the binned training dataset and specifying the index of the parent feature node.\n",
        "\n",
        "#### Report the training and validation accuracies of each Bayes Net. Use get_performance (defined below) by passing in the trained bayes net, binned datasets, and specifying the index of the parent feature node."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssRrH2un6t9d"
      },
      "source": [
        "from pomegranate import *\n",
        "\n",
        "\"\"\"\n",
        "X_train_binned: ndarray (# instances, # features) This is the binned version of the training set\n",
        "y_train: 1darray (# instances,)\n",
        "ind_chosen_parent_features: 1d numpy array encodes the indices of the features relative to FEATURE_NAMES.\n",
        "                            These indices correspond to features that are parent nodes of the heart disease node.\n",
        "ind_chosen_child_features: 1d numpy array encodes the indices of the features relative to FEATURE_NAMES.\n",
        "                            These indices correspond to features that are children nodes of the heart disease node.\n",
        "\n",
        "Returns a BayesianNetwork representing the trained bayes net\n",
        "\"\"\"\n",
        "def construct_and_train_bayes_net(X_train_binned,\n",
        "                                  y_train,\n",
        "                                  ind_chosen_parent_features=np.array([]),\n",
        "                                  ind_chosen_child_features=np.array([]),\n",
        "                                ):\n",
        "    # parent nodes of heart disease\n",
        "\n",
        "    dist_by_parent_feature=[]\n",
        "    state_by_parent_feature=[]\n",
        "    if len(ind_chosen_parent_features)>0:\n",
        "        parent_feature_names_chosen=FEATURE_NAMES[ind_chosen_parent_features]\n",
        "\n",
        "        for ft_index in ind_chosen_parent_features:\n",
        "            ft_dist=DiscreteDistribution.from_samples(X_train_binned[:,ft_index])\n",
        "            dist_by_parent_feature.append(ft_dist)\n",
        "            state_by_parent_feature.append(State(ft_dist, str(FEATURE_NAMES[ft_index])))\n",
        "        dist_by_parent_feature=np.array(dist_by_parent_feature)\n",
        "        state_by_parent_feature=np.array(state_by_parent_feature)\n",
        "\n",
        "\n",
        "    # heart disease node\n",
        "    if len(ind_chosen_parent_features)>0:\n",
        "        X_train_parent_features_binned_with_labels=np.concatenate((X_train_binned[:,ind_chosen_parent_features],\n",
        "                                                                   np.expand_dims(y_train,axis=1)),axis=1)\n",
        "        heartdisease_dist=ConditionalProbabilityTable.from_samples(X_train_parent_features_binned_with_labels)\n",
        "        # temporary workaround to properly initialize the distribution\n",
        "        heartdisease_dist=ConditionalProbabilityTable(heartdisease_dist.parameters[0],dist_by_parent_feature.tolist())\n",
        "    else:\n",
        "        heartdisease_dist=DiscreteDistribution.from_samples(y_train)\n",
        "    heartdisease_state=State(heartdisease_dist, \"heart disease\")\n",
        "\n",
        "    # children node of heart disease\n",
        "\n",
        "    dist_by_child_feature=[]\n",
        "    state_by_child_feature=[]\n",
        "    if len(ind_chosen_child_features)>0:\n",
        "        child_feature_names_chosen=FEATURE_NAMES[ind_chosen_child_features]\n",
        "\n",
        "        for ft_index in ind_chosen_child_features:\n",
        "            X_train_child_features_binned_with_labels=np.concatenate((np.expand_dims(y_train,axis=1),\n",
        "                                                                        np.expand_dims(X_train_binned[:,ft_index],axis=1)),\n",
        "                                                                     axis=1)\n",
        "            ft_dist=ConditionalProbabilityTable.from_samples(X_train_child_features_binned_with_labels)\n",
        "            ft_dist=ConditionalProbabilityTable(ft_dist.parameters[0],[heartdisease_dist])\n",
        "            dist_by_child_feature.append(ft_dist)\n",
        "            state_by_child_feature.append(State(ft_dist, str(FEATURE_NAMES[ft_index])))\n",
        "        dist_by_child_feature=np.array(dist_by_child_feature)\n",
        "        state_by_child_feature=np.array(state_by_child_feature)\n",
        "\n",
        "\n",
        "    pom_model = BayesianNetwork()\n",
        "    pom_model.add_states(*list(state_by_parent_feature))\n",
        "    pom_model.add_states(heartdisease_state)\n",
        "    pom_model.add_states(*list(state_by_child_feature))\n",
        "\n",
        "    for parent_index in np.arange(len(ind_chosen_parent_features)):\n",
        "        pom_model.add_edge(state_by_parent_feature[parent_index],heartdisease_state)\n",
        "\n",
        "    for child_index in np.arange(len(ind_chosen_child_features)):\n",
        "        pom_model.add_edge(heartdisease_state, state_by_child_feature[child_index])\n",
        "\n",
        "    pom_model.bake()\n",
        "\n",
        "    return pom_model\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "pom_model: BayesianNetwork represents the trained bayes net model\n",
        "X_train_binned: ndarray (# instances, # features) This is the binned training set\n",
        "y_train: 1darray (# instances,)\n",
        "X_val_binned: ndarray (# instances, # features) This is the binned validation set\n",
        "y_val: 1darray (# instances,)\n",
        "ind_chosen_parent_features: 1d numpy array encodes the indices of the features relative to FEATURE_NAMES.\n",
        "                            These indices correspond to features that are parent nodes of the heart disease node.\n",
        "ind_chosen_child_features: 1d numpy array encodes the indices of the features relative to FEATURE_NAMES.\n",
        "                            These indices correspond to features that are children nodes of the heart disease node.\n",
        "\n",
        "Returns the training and validation set accuracies attained by the bayes net model (pom_model)\n",
        "\"\"\"\n",
        "def get_performance(pom_model, X_train_binned, y_train, X_val_binned, y_val,\n",
        "                    ind_chosen_parent_features=np.array([]), ind_chosen_child_features=np.array([])):\n",
        "    nones_array=np.expand_dims(np.array([None]*len(X_train_binned)),axis=1)\n",
        "    ind_heartdisease_node=len(ind_chosen_parent_features)\n",
        "    if len(ind_chosen_parent_features)>0:\n",
        "        X_train_binned_with_none=X_train_binned[:,ind_chosen_parent_features]\n",
        "        X_train_binned_with_none=np.concatenate((X_train_binned_with_none,nones_array),axis=1)\n",
        "    else:\n",
        "        X_train_binned_with_none=nones_array\n",
        "\n",
        "    if len(ind_chosen_child_features)>0:\n",
        "        X_train_binned_with_none=np.concatenate((X_train_binned_with_none,\n",
        "                                                X_train_binned[:,ind_chosen_child_features]),\n",
        "                                               axis=1)\n",
        "    pred_labels=np.array(pom_model.predict(X_train_binned_with_none),dtype='int64')[:,ind_heartdisease_node]\n",
        "    train_acc=accuracy_score(y_train, pred_labels)\n",
        "\n",
        "    nones_array=np.expand_dims(np.array([None]*len(X_val_binned)),axis=1)\n",
        "    if len(ind_chosen_parent_features)>0:\n",
        "        X_val_binned_with_none=X_val_binned[:,ind_chosen_parent_features]\n",
        "        X_val_binned_with_none=np.concatenate((X_val_binned_with_none,nones_array),axis=1)\n",
        "    else:\n",
        "        X_val_binned_with_none=nones_array\n",
        "\n",
        "    if len(ind_chosen_child_features)>0:\n",
        "        X_val_binned_with_none=np.concatenate((X_val_binned_with_none,\n",
        "                                               X_val_binned[:,ind_chosen_child_features]),\n",
        "                                               axis=1)\n",
        "    pred_labels=np.array(pom_model.predict(X_val_binned_with_none),dtype='int64')[:,ind_heartdisease_node]\n",
        "    val_acc=accuracy_score(y_val, pred_labels)\n",
        "\n",
        "    return train_acc, val_acc\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCtb-dPC6t9d"
      },
      "source": [
        "# insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wa1O-r86t9e"
      },
      "source": [
        "#### Comment on which feature seems more informative for predicting the presence of heart disease. (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q1tGjCf6t9e"
      },
      "source": [
        "**ANS:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AVRTJ8T6t9e"
      },
      "source": [
        "#### Exercise 2c: Construct a Bayes net with parent and children nodes (3 points)\n",
        "\n",
        "#### Here, we'll implement a Bayes net with both parent nodes and children nodes.\n",
        "\n",
        "#### Construct and train a Bayes net in which:\n",
        "#### -the following features are all parents of the heart disease feature node (age, trestbps, chol).  \n",
        "#### -the following features are all children of the heart disease feature node (thalach, oldpeak, ca).\n",
        "#### Use construct_and_train_bayes_net by passing in the binned training dataset and specifying the indices of the parent feature nodes and indices of the children feature nodes.\n",
        "\n",
        "#### Report the training and validation accuracy of the Bayes Net using get_performance by passing in the trained bayes net, binned datasets, and indices of the parent and children feature nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc3eM-mI6t9e"
      },
      "source": [
        "# insert your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2_t0DHR6t9e"
      },
      "source": [
        "#### Compare the performance of this Bayes net against the Bayes nets from Ex. 2b. (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNdYYylX6t9e"
      },
      "source": [
        "**ANS:**"
      ]
    }
  ]
}