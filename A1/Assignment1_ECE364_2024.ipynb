{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nav_menu": {
      "height": "309px",
      "width": "468px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E32UBMT7VKMm"
      },
      "source": [
        "## Prepare python environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_lm7Q-9VKMn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryOZJYQa3PG0"
      },
      "source": [
        "random_state=5 # use this to control randomness across runs e.g., dataset partitioning"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if running on colab, mount drive to load data, you will be prompted to authorization\n",
        "try:\n",
        "  import google.colab\n",
        "  google.colab.drive.mount('/content/drive')\n",
        "  IN_COLAB = True\n",
        "\n",
        "  proj_path = # TODO\n",
        "  # navigate to the directory containing the project (data and notebook)\n",
        "  import os\n",
        "  os.chdir(proj_path)\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "metadata": {
        "id": "IyI6i6dU_7DP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289cb59b-0638-405c-cab7-949ac26a862a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BASGXrOy4wat"
      },
      "source": [
        "## Preparing the Glass Dataset (2 points)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We will use glass dataset from UCI machine learning repository. Details for this data can be found [here](https://archive.ics.uci.edu/ml/datasets/glass+identification). The objective of the dataset is to identify the class of glass based on the following features:\n",
        "\n",
        "1.  RI: refractive index\n",
        "2.  Na: Sodium\n",
        "3.  Mg: Magnesium\n",
        "4.  Al: Aluminum\n",
        "5.  Si: Silica\n",
        "6.  K: Potassium\n",
        "7.  Ca: Calcium\n",
        "8.  Ba: Barium\n",
        "9.  Fe: Iron\n",
        "10. Type of glass (Target label)\n",
        "\n",
        "The classes of glass are:\n",
        "\n",
        "1. building_windows_float_processed\n",
        "2. building_windows_non_float_processed\n",
        "3. vehicle_windows_float_processed\n",
        "4. containers\n",
        "6. tableware\n",
        "7. headlamps\n",
        "\n",
        "Identification of glass from its content can be used for forensic analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URgO9HCN6RCl"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load the dataset\n",
        "import os\n",
        "if not os.path.exists('glass.csv'):\n",
        "    !wget \"https://github.com/jha-lab/ece364_2024/blob/main/data/glass.csv?raw=true\" -O glass.csv\n",
        "data = pd.read_csv('glass.csv')\n",
        "# Display the first five instances in the dataset\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "Gww6HqHQN7es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgKnqRBm6Wap"
      },
      "source": [
        "### Check the data type for each column"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "rYh0av7JARW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS7PzOS76hrv"
      },
      "source": [
        "#### Look at some statistics of the data using the `describe` function in pandas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "ACjirLEkATLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcVuFlvZ6oYT"
      },
      "source": [
        "1. Count tells us the number of Non-empty rows in a feature.\n",
        "\n",
        "2. Mean tells us the mean value of that feature.\n",
        "\n",
        "3. Std tells us the Standard Deviation Value of that feature.\n",
        "\n",
        "4. Min tells us the minimum value of that feature.\n",
        "\n",
        "5. 25%, 50%, and 75% are the percentile/quartile of each feature.\n",
        "\n",
        "6. Max tells us the maximum value of that feature."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the Data"
      ],
      "metadata": {
        "id": "G_siMrJvxt-d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT6ijHsr6tIc"
      },
      "source": [
        "#### Check how many classes of each type of glass are there in the data. This has been done for you."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\", font_scale=1.8)\n",
        "plt.subplots(figsize = (15,8))\n",
        "sns.countplot(x='Type',data=data).set_title('Count of Glass Types')"
      ],
      "metadata": {
        "id": "w1VD17jzAfto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate `mean` material content for each kind of glass. This has been done for you."
      ],
      "metadata": {
        "id": "lpsJH8g9x71z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute mean material content for each kind of glass\n",
        "data.groupby('Type', as_index=False).mean()"
      ],
      "metadata": {
        "id": "1HHxm1WSAh6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create box plot to see distribution of each content in the glass. See [here](https://seaborn.pydata.org/generated/seaborn.boxplot.html) for further details. This has been done for you."
      ],
      "metadata": {
        "id": "XSL3DWw6yDpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
        "plt.subplots(figsize = (20,15))\n",
        "plt.subplot(3,3,1)\n",
        "sns.boxplot(x='Type', y='RI', data=data)\n",
        "plt.subplot(3,3,2)\n",
        "sns.boxplot(x='Type', y='Na', data=data)\n",
        "plt.subplot(3,3,3)\n",
        "sns.boxplot(x='Type', y='Mg', data=data)\n",
        "plt.subplot(3,3,4)\n",
        "sns.boxplot(x='Type', y='Al', data=data)\n",
        "plt.subplot(3,3,5)\n",
        "sns.boxplot(x='Type', y='Si', data=data)\n",
        "plt.subplot(3,3,6)\n",
        "sns.boxplot(x='Type', y='K', data=data)\n",
        "plt.subplot(3,3,7)\n",
        "sns.boxplot(x='Type', y='Ca', data=data)\n",
        "plt.subplot(3,3,8)\n",
        "sns.boxplot(x='Type', y='Ba', data=data)\n",
        "plt.subplot(3,3,9)\n",
        "sns.boxplot(x='Type', y='Fe', data=data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jeImGCv4AkNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrT0m0GR644-"
      },
      "source": [
        "#### Create a pairplot to display pairwise relationship. See [here](https://seaborn.pydata.org/generated/seaborn.pairplot.html) for further details. This has been done for you."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "sns.pairplot(data[['RI','Na','Mg','Al','Si','Ca','Type']], hue='Type')"
      ],
      "metadata": {
        "id": "x3j4AYMlAnAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot heatmap showing correlation between different features\n",
        "plt.subplots(figsize=(15,10))\n",
        "sns.heatmap(data.corr(),cmap='YlGnBu',annot=True, linewidth=.5)"
      ],
      "metadata": {
        "id": "nTk-F4aIAqJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRhEcln77rIK"
      },
      "source": [
        "### Extract target and descriptive features (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add the following features to the dataset to model interactions between the pairs of glass materials. (See [here](https://cmdlinetips.com/2019/01/3-ways-to-add-new-columns-to-pandas-dataframe/) for an example.)\n",
        "\n",
        "    - Ca*Na\n",
        "    - Al*Mg\n",
        "    - Ca*Mg\n",
        "    - Ca*RI"
      ],
      "metadata": {
        "id": "aX9vAn71yvmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional features to be added to the data\n",
        "data['Ca_Na'] = data.Ca*data.Na\n",
        "data['Al_Mg'] = data.Al*data.Mg\n",
        "data['Ca_Mg'] = data.Ca*data.Mg\n",
        "data['Ca_RI'] = data.Ca*data.RI"
      ],
      "metadata": {
        "id": "R1jKFOsny17i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaNwK8ZtcTWz",
        "outputId": "b9d356f3-53cd-4dcb-d532-8b02109c7ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type',\n",
              "       'Ca_Na', 'Al_Mg', 'Ca_Mg', 'Ca_RI'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Separate the target and features from the data."
      ],
      "metadata": {
        "id": "knewiBP1y5pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store all the features from the data in X\n",
        "X = # TODO\n",
        "# Store all the labels in y\n",
        "y = # TODO"
      ],
      "metadata": {
        "id": "NDIvlRe8BUE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to numpy array\n",
        "X = # TODO\n",
        "y = # TODO"
      ],
      "metadata": {
        "id": "F4UTcWyMBIew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-JPYSnc8JQi"
      },
      "source": [
        "### Create training and validation datasets (1 point)\n",
        "\n",
        "\n",
        "We will split the dataset into training and validation set. Generally in machine learning, we split the data into training,\n",
        "validation and test set (this will be covered in later chapters). The model with best performance on the validation set is used to evaluate perfromance on\n",
        "the test set which is the unseen data. In this assignment, we will using `train set` for training and evaluate the performance on the `validation set` for various\n",
        "model configurations to determine the best hyperparameters (parameter setting yielding the best performance).\n",
        "\n",
        "Split the data into training and validation set using `train_test_split`.  See [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for details. To get consistent result while splitting, set `random_state` to the value defined earlier. We use 80% of the data for training and 20% of the data for validation. This has been done for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzTzI3iT8R5x"
      },
      "source": [
        "X_train,X_val,y_train,y_val = # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REWK434mYIV0"
      },
      "source": [
        "## Training Decision Tree-based Classifiers (18 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv3B5Ne-YIV0"
      },
      "source": [
        "### Exercise 1: Learning a Decision Tree (10 points)\n",
        "\n",
        "#### We will use the `sklearn` library to train a Decision Tree classifier. Review ch.4 and see [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C81hKWIYIV0"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTQ7_HNxYIV0"
      },
      "source": [
        "# tree visualization helper function\n",
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "\n",
        "\"\"\"\n",
        "clf: DecisionTreeClassifier\n",
        "\n",
        "Returns a bytes object representing the image of the tree\n",
        "\"\"\"\n",
        "def get_tree_image(clf):\n",
        "    dot_data = StringIO()\n",
        "    feature_names=data.drop('Type',axis=1).columns\n",
        "    class_names=[\"building_windows_float_processed\", \"building_windows_non_float_processed\", \"vehicle_windows_float_processed\",\n",
        "            \"containers\", \"tableware\", \"headlamps\"]\n",
        "    export_graphviz(clf, out_file=dot_data,\n",
        "                    filled=True, rounded=True,\n",
        "                    special_characters=True,\n",
        "                    feature_names=feature_names,\n",
        "                    class_names=class_names)\n",
        "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "\n",
        "\n",
        "    return graph.create_png()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3kCdj6JYIV1"
      },
      "source": [
        "#### Exercise 1a: Fit and interpret a decision tree. (6 points)\n",
        "\n",
        "#### Fit Decision trees using the Gini index and entropy-based impurity measure.\n",
        "\n",
        "#### Set the random_state to the value defined above. Keep all other parameters at their default values.\n",
        "\n",
        "#### Report the training and validation set accuracies for each classifier."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "uMG083LGBq_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGA4li4YYIV2"
      },
      "source": [
        "#### Visualize the Decision Tree with the best validation performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_clf=# TODO\n",
        "tree_image=get_tree_image(best_clf)\n",
        "Image(tree_image)"
      ],
      "metadata": {
        "id": "PPUAlQ08BxgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_TwnitdYIV3"
      },
      "source": [
        "#### Indicate the most informative descriptive feature (with the threshold) and briefly explain why this is the most informative (from an algorithmic viewpoint)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rWlhohiYIV3"
      },
      "source": [
        "ANS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt6seCSGYIV3"
      },
      "source": [
        "#### Briefly comment on the tree's depth and what factors may contribute to the shallowness/complexity of the tree.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG-uaUdnYIV4"
      },
      "source": [
        "ANS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4FP3xEFYIV4"
      },
      "source": [
        "#### Show how one can interpret the tree by specifying the rule from its left most branch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Ir6AIwYIV4"
      },
      "source": [
        "ANS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEC5UKZ0YIV4"
      },
      "source": [
        "#### Exercise 1b: Prune a decision tree. (2 points)\n",
        "\n",
        "#### Next, let's try pruning the tree to see if we can improve the classifier's generalization performance.\n",
        "\n",
        "####  Preprune a decision tree by varying the `max_depth` among {None (no depth control), 1,3,5,7}.\n",
        "\n",
        "#### Set the criterion to entropy and the random_state to the value defined above. Keep all other parameters at their default values.\n",
        "\n",
        "#### Report the training and validation set accuracies for each classifier."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "SH8Diia1CalF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpRQ3WkqYIV5"
      },
      "source": [
        "#### Analyze the effect of increasing tree depth on training and validation performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAoUPfXxYIV5"
      },
      "source": [
        "ANS:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 1c: Postprune a decision tree. (2 points)\n",
        "\n",
        "#### Implement reduced error pruning on the two decision trees that you previously trained in Exercise 1a. Use the validation set to decide which nodes to prune.\n",
        "\n",
        "#### Report the validation set accuracies for each classifier after pruning.\n",
        "\n",
        "#### The pruning function is partly writen, please fill in the TODO part. Review ch.4.4.4 for more details."
      ],
      "metadata": {
        "id": "4aXBtCQlaP6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit new trees if you want to keep the trees in 1a unmodified\n",
        "gini_clf = # TODO: your tree fitted using the Gini index\n",
        "entropy_clf = # TODO: your tree fitted using the entropy-based impurity measure\n",
        "\n",
        "def reduced_error_pruning(dtree, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Perform reduced error pruning on a decision tree classifier.\n",
        "\n",
        "    This function directly modifies the decision tree passed as an argument.\n",
        "\n",
        "    Args:\n",
        "    dtree: DecisionTreeClassifier\n",
        "        The decision tree to prune, must be already fitted.\n",
        "    X_val: array-like\n",
        "        Validation features used to prune the tree.\n",
        "    y_val: array-like\n",
        "        Validation labels used to determine pruning effectiveness.\n",
        "\n",
        "    Returns:\n",
        "    dtree: DecisionTreeClassifier\n",
        "        The pruned decision tree.\n",
        "    \"\"\"\n",
        "\n",
        "    # Access the internal tree structure to identify non-leaf nodes\n",
        "    non_leaf_nodes = [i for i in range(dtree.tree_.node_count) if dtree.tree_.children_left[i] != dtree.tree_.children_right[i]]\n",
        "\n",
        "    # Track the best accuracy and corresponding tree configuration. initialize with original accuracy.\n",
        "    best_acc = # TODO\n",
        "\n",
        "    # Iterate over non-leaf nodes in reverse order to consider pruning from the bottom up\n",
        "    for i in reversed(non_leaf_nodes):\n",
        "        # Store current node children to restore if needed\n",
        "        left, right = dtree.tree_.children_left[i], dtree.tree_.children_right[i]\n",
        "\n",
        "        # Temporarily make the node a leaf\n",
        "        dtree.tree_.children_left[i], dtree.tree_.children_right[i] = -1, -1\n",
        "\n",
        "        # Calculate the accuracy of the tree with the node pruned (turned into a leaf)\n",
        "        temp_acc = # TODO\n",
        "\n",
        "        if temp_acc < best_acc: # Revert pruning if accuracy decreases\n",
        "            # Restore the node to its original state\n",
        "            # TODO\n",
        "        else:\n",
        "            # Update the best accuracy observed\n",
        "            # TODO\n",
        "\n",
        "    return dtree  # Return the modified tree\n",
        "\n",
        "\n",
        "pruned_entropy = reduced_error_pruning(entropy_clf, X_val, y_val)\n",
        "pruned_entropy_acc = # TODO\n",
        "print(f\"Validation accuracy of entropy tree after pruning: {pruned_entropy_acc:.4f}\")\n",
        "\n",
        "pruned_gini = reduced_error_pruning(gini_clf, X_val, y_val)\n",
        "pruned_gini_acc = # TODO\n",
        "print(f\"Validation accuracy of gini tree after pruning: {pruned_gini_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "4GQ1tIWBWF-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKyvUPDDYIV5"
      },
      "source": [
        "### Exercise 2: Learning an Ensemble of Decision Trees (8 points)\n",
        "\n",
        "#### We will use the `sklearn` library to implement bagging and boosting. Review ch.4 and read more on [bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_KyixXJYIV6"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_8gehq1YIV6"
      },
      "source": [
        "#### Exercise 2a: Fit a Random Forest. (4 points)\n",
        "\n",
        "#### Fit different Random Forest classifiers by varying the number of trees among {10, 50, 100, 400, 1000}.\n",
        "\n",
        "#### Set the `criterion` to entropy and set the random_state to the value defined above. Keep all other parameters at their default values.\n",
        "\n",
        "#### Report the validation set accuracies for each classifier."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "QLrkDFSSCuHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO5IChrMYIV6"
      },
      "source": [
        "#### Comment on the effect of increasing the number of trees on validation performance. Compare the performance of the best performing Random Forest classifier against the Decision Tree Classifier trained with entropy (Ex. 1a) and explain any difference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvLyteZUYIV6"
      },
      "source": [
        "ANS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY3bcqkeYIV7"
      },
      "source": [
        "#### Exercise 2b: Fit a Gradient Boosted Decision Tree (GBDT). (4 points)\n",
        "\n",
        "#### Fit different GBDTs by varying the number of boosting steps/trees added among {5, 10, 20, 50, 100, 200}.\n",
        "\n",
        "#### Set the `n_iter_no_change` to 100, `validation_fraction=0.2`, and random_state to the value defined above. Keep all other parameters at their default values.\n",
        "\n",
        "#### Report the training and validation set accuracies for each classifier."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "_DxDDbwYC6HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9mRWIkMYIV7"
      },
      "source": [
        "#### Comment on the effect of increasing the number of trees on validation performance. Compare the performance of the best performing GBDT against that of the best performing Random Forest classifier (Ex. 2a) and Decision Tree classifier trained with entropy (Ex. 1a)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlmAQQOyYIV7"
      },
      "source": [
        "ANS:"
      ]
    }
  ]
}